{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: radon in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: mando<0.8,>=0.6 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from radon) (0.7.1)\n",
      "Requirement already satisfied: colorama>=0.4.1 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from radon) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from mando<0.8,>=0.6->radon) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -sonschema (c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -sonschema (c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install radon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset = pd.read_csv(\"Python_LongMethodSmell_Dataset.csv\")\n",
    "\n",
    "# Define the 12 features you want to select and normalize\n",
    "selected_features = [\n",
    "    'difficulty', 'scloc', 'effort', 'time', 'volume',\n",
    "    'bugs', 'lloc', 'calculated_length'\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with only the selected features\n",
    "selected_dataset = dataset[selected_features]\n",
    "\n",
    "# Create a Min-Max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the scaler on the selected features\n",
    "selected_dataset = pd.DataFrame(scaler.fit_transform(selected_dataset), columns=selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from radon.raw import analyze\n",
    "from radon.metrics import h_visit\n",
    "import ast\n",
    "\n",
    "# Step 1: Extract code metrics using Radon\n",
    "def extract_metrics(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        source_code = file.read()\n",
    "    \n",
    "    metrics = analyze(source_code)\n",
    "    \n",
    "    # Use the ast module from the Python standard library\n",
    "    ast_node = ast.parse(source_code)\n",
    "    \n",
    "    halstead_metrics = h_visit(ast_node)\n",
    "\n",
    "    return metrics, halstead_metrics\n",
    "\n",
    "# Step 2: Save metrics in a Pandas DataFrame\n",
    "def create_dataframe(file_paths):\n",
    "    data = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        metrics, halstead_metrics = extract_metrics(file_path)\n",
    "        \n",
    "        # Access metrics from the 'total' attribute of Halstead\n",
    "        row_data = {\n",
    "            'difficulty': halstead_metrics.total.difficulty,\n",
    "            'scloc': metrics.sloc,\n",
    "            'effort': halstead_metrics.total.effort,\n",
    "            'time': halstead_metrics.total.time,\n",
    "            'volume': halstead_metrics.total.volume,\n",
    "            'bugs': halstead_metrics.total.bugs,\n",
    "            'lloc': metrics.lloc,\n",
    "            'calculated_length': halstead_metrics.total.calculated_length,\n",
    "            #'loc': metrics.loc,\n",
    "            #'comments': metrics.comments,\n",
    "            #'single_comments': metrics.single_comments,\n",
    "            #'multi_comments': metrics.multi,\n",
    "            #'blanks': metrics.blank,\n",
    "            #'h1': halstead_metrics.total.h1,\n",
    "            #'h2': halstead_metrics.total.h2,\n",
    "            #'n1': halstead_metrics.total.N1,\n",
    "            #'n2': halstead_metrics.total.N2,\n",
    "            #'vocabulary': halstead_metrics.total.vocabulary,\n",
    "            #'length': halstead_metrics.total.length,\n",
    "        }\n",
    "\n",
    "        data.append(row_data)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Step 3: Normalize the DataFrame using MinMaxScaler\n",
    "def normalize_dataframe(df):\n",
    "    normalized_df = pd.DataFrame(scaler.transform(df), columns=df.columns)\n",
    "    return normalized_df\n",
    "\n",
    "# Step 4: Load the XGBoost model\n",
    "def load_model(model_path):\n",
    "    with open(model_path, 'rb') as file:\n",
    "        model = joblib.load(file)\n",
    "    return model\n",
    "\n",
    "# Step 5: Predict using the loaded model\n",
    "def predict_data(model, data):\n",
    "    predictions = model.predict(data)\n",
    "    predictions = predictions.astype(int)\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "file_paths = ['code_example/long_method_example.py','code_example/non_long_method_example.py']  # Add more file paths if needed\n",
    "data_frame = create_dataframe(file_paths)\n",
    "normalized_data = normalize_dataframe(data_frame)\n",
    "\n",
    "model_path = 'model/xgboost_long_method_model.pkl'\n",
    "xgboost_model = load_model(model_path)\n",
    "\n",
    "predictions = predict_data(xgboost_model, normalized_data)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bayug\\Documents\\GitHub\\python-code-smell\\long_method_detector.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bayug/Documents/GitHub/python-code-smell/long_method_detector.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Load your trained XGBoost model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bayug/Documents/GitHub/python-code-smell/long_method_detector.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bayug/Documents/GitHub/python-code-smell/long_method_detector.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mmodel/xgboost_long_method_model.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# Replace 'your_model.pkl' with the path to your saved model file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bayug/Documents/GitHub/python-code-smell/long_method_detector.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Specify the index of the tree you want to visualize\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bayug/Documents/GitHub/python-code-smell/long_method_detector.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tree_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Change this to the index of the tree you want to visualize\u001b[39;00m\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\xgboost\\sklearn.py:777\u001b[0m, in \u001b[0;36mXGBModel.load_model\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_Booster\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    776\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m Booster({\u001b[39m\"\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs})\n\u001b[1;32m--> 777\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49mload_model(fname)\n\u001b[0;32m    778\u001b[0m meta_str \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_booster()\u001b[39m.\u001b[39mattr(\u001b[39m\"\u001b[39m\u001b[39mscikit_learn\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    779\u001b[0m \u001b[39mif\u001b[39;00m meta_str \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    780\u001b[0m     \u001b[39m# FIXME(jiaming): This doesn't have to be a problem as most of the needed\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# information like num_class and objective is in Learner class.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\xgboost\\core.py:2444\u001b[0m, in \u001b[0;36mBooster.load_model\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m   2440\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, (\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike)):\n\u001b[0;32m   2441\u001b[0m     \u001b[39m# assume file name, cannot use os.path.exist to check, file can be\u001b[39;00m\n\u001b[0;32m   2442\u001b[0m     \u001b[39m# from URL.\u001b[39;00m\n\u001b[0;32m   2443\u001b[0m     fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(fname))\n\u001b[1;32m-> 2444\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterLoadModel(\n\u001b[0;32m   2445\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, c_str(fname)))\n\u001b[0;32m   2446\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mbytearray\u001b[39m):\n\u001b[0;32m   2447\u001b[0m     buf \u001b[39m=\u001b[39m fname\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your trained XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model('model/xgboost_long_method_model.pkl')  # Replace 'your_model.pkl' with the path to your saved model file\n",
    "\n",
    "# Specify the index of the tree you want to visualize\n",
    "tree_index = 0  # Change this to the index of the tree you want to visualize\n",
    "\n",
    "# Visualize the specified tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "xgb.plot_tree(model, num_trees=tree_index)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bayug\\Documents\\GitHub\\python-code-smell\\long_method_detector.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bayug/Documents/GitHub/python-code-smell/long_method_detector.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgraphviz\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bayug/Documents/GitHub/python-code-smell/long_method_detector.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Visualize the entire ensemble (may not be practical for a large number of trees)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bayug/Documents/GitHub/python-code-smell/long_method_detector.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m xgb\u001b[39m.\u001b[39mto_graphviz(model, num_trees\u001b[39m=\u001b[39mtree_index)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tree_index' is not defined"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "# Visualize the entire ensemble (may not be practical for a large number of trees)\n",
    "xgb.to_graphviz(model, num_trees=tree_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
