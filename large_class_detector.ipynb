{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: radon in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: mando<0.8,>=0.6 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from radon) (0.7.1)\n",
      "Requirement already satisfied: colorama>=0.4.1 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from radon) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from mando<0.8,>=0.6->radon) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -sonschema (c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -sonschema (c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install radon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "dataset = pd.read_csv(\"Python_LargeClassSmell_Dataset.csv\")\n",
    "\n",
    "# Define the 12 features you want to select and normalize\n",
    "selected_features = [\n",
    "    'difficulty', 'scloc', 'loc', 'effort', 'time', 'volume',\n",
    "    'bugs', 'lloc', 'comments', 'blanks', 'single_comments',\n",
    "    'calculated_length'\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with only the selected features\n",
    "selected_dataset = dataset[selected_features]\n",
    "\n",
    "# Create a Min-Max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the scaler on the selected features\n",
    "selected_dataset = pd.DataFrame(scaler.fit_transform(selected_dataset), columns=selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large_class_example.py memiliki code smell large class\n",
      "non_large_class_example.py tidak memiliki code smell large class\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from radon.raw import analyze\n",
    "from radon.metrics import h_visit\n",
    "import ast\n",
    "import os\n",
    "\n",
    "# Step 1: Extract code metrics using Radon\n",
    "def extract_metrics(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        source_code = file.read()\n",
    "    \n",
    "    metrics = analyze(source_code)\n",
    "    \n",
    "    # Use the ast module from the Python standard library\n",
    "    ast_node = ast.parse(source_code)\n",
    "    \n",
    "    halstead_metrics = h_visit(ast_node)\n",
    "\n",
    "    return metrics, halstead_metrics\n",
    "\n",
    "# Step 2: Save metrics in a Pandas DataFrame\n",
    "def create_dataframe(file_paths):\n",
    "    data = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        metrics, halstead_metrics = extract_metrics(file_path)\n",
    "        \n",
    "        # Access metrics from the 'total' attribute of Halstead\n",
    "        row_data = {\n",
    "            'difficulty': halstead_metrics.total.difficulty,\n",
    "            'scloc': metrics.sloc,\n",
    "            'loc': metrics.loc,\n",
    "            'effort': halstead_metrics.total.effort,\n",
    "            'time': halstead_metrics.total.time,\n",
    "            'volume': halstead_metrics.total.volume,\n",
    "            'bugs': halstead_metrics.total.bugs,\n",
    "            'lloc': metrics.lloc,\n",
    "            'comments': metrics.comments,\n",
    "            'blanks': metrics.blank,\n",
    "            'single_comments': metrics.single_comments,\n",
    "            'calculated_length': halstead_metrics.total.calculated_length,\n",
    "            #'multi_comments': metrics.multi,\n",
    "            #'h1': halstead_metrics.total.h1,\n",
    "            #'h2': halstead_metrics.total.h2,\n",
    "            #'n1': halstead_metrics.total.N1,\n",
    "            #'n2': halstead_metrics.total.N2,\n",
    "            #'vocabulary': halstead_metrics.total.vocabulary,\n",
    "            #'length': halstead_metrics.total.length,\n",
    "        }\n",
    "\n",
    "        data.append(row_data)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Step 3: Normalize the DataFrame using MinMaxScaler\n",
    "def normalize_dataframe(df):\n",
    "    normalized_df = pd.DataFrame(scaler.transform(df), columns=df.columns)\n",
    "    return normalized_df\n",
    "\n",
    "# Step 4: Load the XGBoost model\n",
    "def load_model(model_path):\n",
    "    with open(model_path, 'rb') as file:\n",
    "        model = joblib.load(file)\n",
    "    return model\n",
    "\n",
    "# Step 5: Predict using the loaded model\n",
    "def predict_data(model, data):\n",
    "    predictions = model.predict(data)\n",
    "    predictions = predictions.astype(int)\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "file_paths = ['code_example/large_class_example.py','code_example/non_large_class_example.py']  # Add more file paths if needed\n",
    "data_frame = create_dataframe(file_paths)\n",
    "normalized_data = normalize_dataframe(data_frame)\n",
    "\n",
    "model_path = 'model\\dt_large_class_model.pkl'\n",
    "model = load_model(model_path)\n",
    "\n",
    "predictions = predict_data(model, normalized_data)\n",
    "for i, prediction in enumerate(predictions):\n",
    "    file_name = os.path.basename(file_paths[i])  # Extract file name from path\n",
    "    if prediction:  # Prediction indicates code smell\n",
    "        print(f\"{file_name} memiliki code smell large class\")\n",
    "    else:\n",
    "        print(f\"{file_name} tidak memiliki code smell large class\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
